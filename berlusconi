#!/usr/bin/python3
# Import libraries and modules
from bs4 import BeautifulSoup as B
import re
import urllib
from time import sleep
import os
import mysql.connector as my
from mysql.connector import Error
from mysql.connector import errorcode

####################### CHANGE THIS FOR DIFFERENT HTML FILES##############################
# put html into file variable and open it
html_file = "/root/Capstone/berlusconi/BURLUSCONI/Software&Malware/BERLUSCONI MARKET3.html"
page = open(html_file)

# Create BS object
soup = B(page.read(), features='lxml')

# try to get vendor names and write them in a file
# open 'vendor.txt' file in write mode.
vendors = open("vendors.txt", "w")
# get the required information between the 'div' html tags
vendor_html = soup.find_all("div", class_="user-details")
vendor_html = str(vendor_html)

# begin loop to get vendor name and clean it
for i in re.findall(r'(?<=>)\b\w+',vendor_html):
        vendors.write(i)
        vendors.write("\n")


#close file
vendors.close()

# find the product
product_html = soup.find_all("div", class_="item-details")
product_html = str(product_html)

# open 'products.txt' file in write mode
products = open("products.txt", "w")

# begin loop to get product detail and clean it
for i in re.findall(r'(?<=<b>)(.*?)(?=<\/b>)',product_html):
	i = re.sub(",",'',i)
	products.write(i)
	products.write("\n")
#close file
products.close()

# find the prices
price_html = soup.findAll("div", {"class": "col-xs-3 text-right listing-price"})
price_html = str(price_html)

# open file for prices
prices = open("prices.txt", "w")

# looping again ....
for i in re.findall(r'(?<=<strong>)(.*?)(?=<b>)',price_html):
        prices.write(i)
        prices.write("\n")
# close file
prices.close()

# combine all the text files into a CSV file
create_csv = os.popen("paste -d',' products.txt prices.txt vendors.txt > sql_malware.csv")
copy_csv = os.popen("cp sql_malware.csv /var/lib/mysql/Berlusconi/sql_malware.csv")

#MySQL stuff
try:
	conn = my.connect(
		host='localhost',
		user='root',
		password='P@ssw0rd',
		allow_local_infile=True,
		db='Berlusconi'
	)
except ValueError:
        print("Connection Error")
try:
        cursor = conn.cursor()
        query = '''load data local infile '/root/Capstone/berlusconi/BURLUSCONI/Mal_out/sql_malware.csv' into table Malware fields terminated by ',';'''
        cursor.execute(query)
        conn.commit()
        conn.close()
except ValueError:
        print("QUEERY ERROR!")

# Clean up temporary files
def cleanup():
        sleep(1)
        delete_csv = os.popen("rm /var/lib/mysql/Berlusconi/sql_malware.csv")
        delte_files = os.popen("rm /root/Capstone/berlusconi/BURLUSCONI/Mal_out/sql_malware.csv *.txt")
cleanup()
